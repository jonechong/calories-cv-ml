{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Combing Notebook \n",
    "This notebook aims to retrieve images from the internet for the purpose of dataset creation due to the scarcity of accessible, quality food dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import configparser\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs.ini')\n",
    "api_key = config['API']['custom_search_api_key']\n",
    "cx = config['API']['custom_search_cx']\n",
    "user_agent = config['UserAgents']['user_agent']\n",
    "geolocation = config['API']['geolocation']\n",
    "host_language = config['API']['host_language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Custom Search JSON API clien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = build(\"customsearch\", \"v1\", developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_images(query, total_num_images, geolocation, host_language, start_num=1, retries=3):\n",
    "    search_results = []\n",
    "    start_index = start_num  # Start at the specified index of the results\n",
    "\n",
    "    while len(search_results) < total_num_images:\n",
    "        try:\n",
    "            # Make a request to the API\n",
    "            res = service.cse().list(\n",
    "                q=query,  # Query string\n",
    "                cx=config['API']['custom_search_cx'],  # Custom search engine ID from the config file\n",
    "                searchType='image',  # Search for images\n",
    "                num=min(10, total_num_images - len(search_results)),  # Number of results per request (max 10)\n",
    "                start=start_index  # Start index for results\n",
    "            ).execute()\n",
    "\n",
    "            # Add the results to our list, and increment the start index\n",
    "            search_results.extend(res.get('items', []))\n",
    "            start_index += len(res.get('items', []))\n",
    "\n",
    "            # If there are no more results, break the loop\n",
    "            if 'nextPage' not in res:\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            retries -= 1\n",
    "            if retries <= 0:\n",
    "                print(\"Max retries reached. Exiting.\")\n",
    "                break\n",
    "            print(\"Retrying...\")\n",
    "            time.sleep(1)  # Wait for 1 second before retrying\n",
    "\n",
    "    return search_results[:total_num_images]\n",
    "\n",
    "def download_images(image_urls, save_folder):\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    \n",
    "    for i, img_url in enumerate(image_urls):\n",
    "        try:\n",
    "            response = requests.get(img_url, headers={'User-Agent': user_agent})\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "            \n",
    "            # You could also check MIME type here to ensure result is an image\n",
    "            content_type = response.headers['Content-Type']\n",
    "            if 'image' in content_type:\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "                image_format = content_type.split('/')[-1]  # 'jpeg', 'png', etc.\n",
    "                image.save(os.path.join(save_folder, f'image_{i+1}.{image_format}'))\n",
    "                print(f\"Downloaded image {i+1}\")\n",
    "            else:\n",
    "                print(f\"URL {i+1} does not seem to be an image.\")\n",
    "        except requests.HTTPError as http_err:\n",
    "            print(f\"HTTP error occurred: {http_err}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Other error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_food = 'hainanese chicken rice'\n",
    "search_queries = ['Singaporean chicken rice', 'Malaysian chicken rice', 'chinese chicken rice']\n",
    "no_of_imgs = 190\n",
    "#This refers to the number of images you already have. \n",
    "#So if you already have 30 images, this value will be 30\n",
    "# Note that the api really only allows you to fetch 200 images, even though the documentation says 100 images of results.\n",
    "start_num = 200\n",
    "# download_directory = f'../data/{search_query.replace(\" \", \"_\")}' # Replace directory with desired path\n",
    "download_directory = f'../data/{target_food.replace(\" \", \"_\")}' # Replace directory with desired path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for search_query in search_queries:\n",
    "    images = fetch_images(cx, search_query, no_of_imgs, geolocation, host_language)\n",
    "    image_links = [image['link'] for image in images]\n",
    "    download_images(image_links, download_directory, start_num)\n",
    "    start_num += no_of_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call fetch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = fetch_images(cx, search_query, no_of_imgs, geolocation, host_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve images links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_links = [image['link'] for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(image_links, download_directory, start_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calories-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
